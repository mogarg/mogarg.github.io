[{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"https://mogarg.github.io/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\n Don’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution.    ","permalink":"https://mogarg.github.io/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"https://mogarg.github.io/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"https://mogarg.github.io/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":"This article presents a summary of the paper by Lalith Suresh, Dahlia Malkhi, Parikshit Gopalan, Ivan Porto Carreiro, and Zeeshan Lokhandwala, which appeared in USENIX Annual Technical Conference 2018. I also presented this paper in the Distributed Systems Reading Group, a weekly public paper reading group hosted by Prof Murat Debirmas.\nThis paper primarily about membership in distributed systems in the presence of gray failures. While crash faults are relatively easy to detect and fix, gray failures often go undetected or take a long time to localize and fix. The authors whet our interests by setting up an experiment in a 400 node akka cluster which works on a gossip based membership model. They wait for the cluster to stabilize i.e. each node outputs the size of the members list.\nThey now introduce packet-loss failures in 1% of nodes. This is where everything goes haywire. Due to the nature of the gossip based membership service, the correct nodes start to accuse each other and the membership view becomes unstable. At times, even some benign processes are removed from the membership view. This is problematic because expensive failure recovery and data migration services are triggered on view-change. In case of an unstable membership service this can lead to performance degradation and outages.\nAdditionaly, at any given time during the different nodes have different views of the membership. In the presence of inconsistencies, any service which utilize the membership service to get the ground truth about the cluster would not work properly.\nHence, this paper is about two features that the authors contend are inadequate in membership services today.\n Stability: robustness against asymmetric network failures, flip-flops, packet losses etc. Consistency: the processes see the same sequence of membership changes.  The solution which espouses these features is Rapid: A Distributed Membership Service at Scale. The service consists of three main components which follow a functional order.\n Monitoring Overlay. Membership change proposal. View-Change consensus  Monitoring Overlay A monitoring overlay is formed with each node is monitored by K nodes. In this case a node that monitors is called an observer, and the observee is called a subject.\nConstruction of the overlay The monitoring overlay is based on an expander graph. Expander graphs are graphs with a low degree and high connectivity. The authors use K pseudo-random rings to form an expander graph due to the fact that,\n .. a random K-regular graph is very likely to be a good expander for K $\\geq$ 3.\n Specifically, in a ring containing the full list of members, a pair of processes (o, s) form an observer/subject edge if o precedes s in a ring.\nK is small (could be 10 even if the cluster size is 1000). The observers form a directed graph to the subjects. Rapid follows a template based model where the edge-failure detectors are provided by the user. These detectors could range from a simple heartbeat to observing TCP packets and application monitoring state.\nMonitoring alerts like REMOVE (on detecting failure) and JOIN are disseminated by the observers using scalable best-effort broadcast. Furthermore, these alerts are irrevocable.\nMulti-process cut detection Each process maintains a M(o, s) which is set to 1 if an alert is received from an observer o about proces s. The alert tally for a subject s is tally(s) = M(*, s). A process would,\n delay proposing a configuration change until there is at least one process in stable report mode and there is no process in unstable report mode.\n A process s is considered to be in stable report mode by a process p if there exist at least H (high watermark) alerts about s, otherwise s is in an unstable report mode is in between L and H where 1 $\\leq$ L $\\leq$ H $\\leq$ K.\nSpecial cases Processes s can get stuck in unstable mode if,\n An observer o for s is itself faulty. In this case an implicit-alert is applied from o to s. A process s has a good connection with a subset of observers, but bad with others. In this case, if s is in unstable mode for a certain time period, the observers echo the alert about s.  After this stage each process have a new configuration to send to other processes.\nView-change with consensus A consistent configuration is achieved by treating the cut detected by each process from the previous stage as a proposal to a Fast Paxos instance.\n The counting protocol itself uses gossip to disseminate and aggregate a bitmap of “votes” for each unique proposal. Each process sets a bit in the bitmap of a proposal to reflect its vote. As soon as a process has a proposal for which three quarters of the cluster has voted, it decides on that proposal.\n Evaluation Compared against Zookeeper (Logically centralized configuration service) and Memberlist (Gossip based membership).\nRapid provides,\n Better bootstrap times   Robustness in the presence of packet loss.   , and in the case of network partitions  Presentation   ","permalink":"https://mogarg.github.io/blog/05-24-2020-rapid-membership/","tags":["membership","distributed systems","gray failures","cloud"],"title":"Rapid: Distributed Membership Service at Scale"},{"categories":null,"contents":"Thesis My thesis can be found here.\nMotivation While internet services are designed and deployed with an assumption of perimeter less security at the application layer, most production distributed systems today are designed assuming a classical Crash Fault Tolerant (CFT) model. In realistic deployment scenarios, keeping track of all bridged networks such as smartphones, network printers, etc. is almost impossible. Hence, designing distributed systems without considering the possibility of an active adversary makes the system vulnerable from its core. While there exists extensive research on Byzantine Fault Tolerant (BFT) systems, overheads associated with such solutions preclude widespread adoption.\nProblems Cross Fault Tolerance (XFT) by Liu et al. addresses this problem by providing stronger consistency and availability guarantees than both the CFT and BFT under the assumption that a majority of replicas are correct and can communicate with each other synchronously. XPaxos designed by Liu et al. assuming the XFT model achieves similar throughput and latency as Paxos. However, it brings two challenges. One it fails to provide comparable performance as the number of faults are higher than one. Secondly, since it is reliant on a single leader for ordering commands, it suffers from similar bottlenecks as Multi-Paxos, the widely adopted and deployed version of Paxos. Designing a multi-leader consensus algorithm like M2Paxos can solve the second problem. However, M2Paxos does not guarantee liveness under contention, and the Byzantine nodes in the system can further exacerbate this problem by increasing the conflicting commands.\nSolution To solve the problem of liveness in M2Paxos, I designed a leader-election algorithm which provides liveness while providing weak-consistency for object ownership. The weak consistency assumption implies that even though all nodes don\u0026rsquo;t agree on a single leader for objects accessed by conflicting commands at all times, they can have these commands decided by forwarding their request to a node that they have elected as the leader. Ultimately, if there are no new conflicting commands proposed all nodes agree on a unique leader. The ownership acquisition for commands don\u0026rsquo;t conflict can still execute in parallel. To make this Byzantine Fault-Tolerant I plan to use Verifiable Random Functions where nodes generate random tags which can be verified by other nodes. This algorithm can be leveraged to design a multi-leader Byzantine Fault Tolerant consensus algorithm which provides higher performance than XPaxos and which does not incur extra deployment costs.\n","permalink":"https://mogarg.github.io/projects/creations/elpis/","tags":["Distributed Systems","Byzantine Fault-Tolerance","Blockchains","DHT","Java"],"title":"Elpis"},{"categories":null,"contents":"Apollo is a ticketing management system prototype. Musical events have several stakeholders like the music label, the venue management and the artist themself. This smart-contract adds transparency to the process. Major features include:\n Buying tickets for a show, requiring the correct amount tickets cost Transferring tickets to other wallets Verifying ownership of tickets through contract methods.  For more information, please check out https://github.com/mogarg/Apollo)\n","permalink":"https://mogarg.github.io/projects/creations/apollo/","tags":["Hyperledger","Blockchains","Golang","Node.js"],"title":"Apollo"},{"categories":null,"contents":"I helped found the Mobile Development Team at Indus Valley Partners by working on several applications including IVP Nebula. IVP Nebula, enables alternative asset managers to access Key Performance Indicators, Portfolio Insights, Enterprise Data.\nKey Features I was involved from the ideation stage and contributed to key features:\n Power Optimization: Developed query processing and caching strategies for optimizing power consumption. Security: Developed a library to provide easy access to File Encryption, Network Communication based on Crytographic Hashing/Encryption algorithms provided by the Common Crypto Framework. High-Performance Calculations: Developed a library to provide high-performance on-device arithmetic calculations using SIMD instructions provided by the Accelerate Framework. Multi-Source Integration: Flexible integration with IVP Polaris, Stratus (Enterprise/Cloud Warehouse solutions) and in house data storage systems, excel files and pulling in that data onto mobile device. Dashboard Store: Added a \u0026ldquo;store\u0026rdquo; where custom dashboards/analytics can be created and shared from a Web Dashboard which can then be interacted with natively on Mobile. Sharing: Exporting to PDF, Excel with sharing via Email or Integrated Messaging.  Users  By Portfolio managers/Traders to access P\u0026amp;L reports, Market data and Trading. By IR/Marketing team to Investor/Performance data. By Chief compliance officers access to real time compliance violations/alerts.  ","permalink":"https://mogarg.github.io/projects/creations/nebula/","tags":["iOS","Swift","Objective-C"],"title":"Nebula"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ] ","permalink":"https://mogarg.github.io/search/","tags":null,"title":"Search Results"}]